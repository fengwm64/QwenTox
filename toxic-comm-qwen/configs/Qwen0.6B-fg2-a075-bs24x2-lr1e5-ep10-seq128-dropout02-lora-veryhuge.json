{
  "model_name_or_path": "/home/fwm/projects/Toxic-comment-classification/models/ar_models/qwen/Qwen3-0.6B-Base",
  "data_dir": "/home/fwm/projects/Toxic-comment-classification/data/jigsaw-toxic-comment",
  "output_dir": "/home/fwm/projects/Toxic-comment-classification/toxic-comm-qwen/results/Qwen0.6B-fg2-a075-bs24x2-lr1e5-ep10-seq128-dropout02-lora-veryhuge",
  "seed": 1056,
  "do_train": true,
  "do_eval": true,
  "per_device_train_batch_size": 32,
  "per_device_eval_batch_size": 64,
  "gradient_accumulation_steps": 2,
  "loss_type": "focal",
  "focal_loss_gamma": 2.0,
  "focal_loss_alpha": 0.75,
  "learning_rate": 1e-5,
  "num_train_epochs": 10,
  "classifier_dropout": 0.2,
  "use_lora": true,
  "lora_r": 64,
  "lora_alpha": 128,
  "lora_dropout": 0.25,
  "max_seq_length": 128,
  "logging_steps": 10,
  "save_strategy": "steps",
  "save_steps": 100,
  "save_total_limit": 8,
  "eval_strategy": "steps",
  "eval_steps": 100,
  "bf16": true,
  "ddp_find_unused_parameters": false,
  "overwrite_output_dir": true,
  "use_swanlab": true,
  "swanlab_project": "Toxic-Comm-Qwen",
  "swanlab_workspace": "ddl",
  "swanlab_experiment_name": "Qwen0.6B-fg2-a075-bs24x2-lr1e5-ep10-seq128-dropout02-lora-veryhuge"
}